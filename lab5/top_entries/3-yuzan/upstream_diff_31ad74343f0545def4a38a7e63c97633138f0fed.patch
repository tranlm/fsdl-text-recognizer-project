diff --git a/lab1/text_recognizer/models/character_model.py b/lab1/text_recognizer/models/character_model.py
index fbd0afd..6be5c2c 100644
--- a/lab1/text_recognizer/models/character_model.py
+++ b/lab1/text_recognizer/models/character_model.py
@@ -21,7 +21,11 @@ class CharacterModel(Model):
             image = (image / 255).astype(np.float32)
         # NOTE: integer to character mapping dictionary is self.data.mapping[integer]
         ##### Your code below (Lab 1)
-
+        probas = self.network.predict(np.array([image]), batch_size=1)
+        artifact = probas.flatten()
+        pred_cls = np.argmax(artifact)
+        predicted_character = self.data.mapping[pred_cls]
+        confidence_of_prediction = artifact[pred_cls]
         ##### Your code above (Lab 1)
         return predicted_character, confidence_of_prediction
 
diff --git a/lab1/text_recognizer/networks/mlp.py b/lab1/text_recognizer/networks/mlp.py
index 7dac32f..b78b76e 100644
--- a/lab1/text_recognizer/networks/mlp.py
+++ b/lab1/text_recognizer/networks/mlp.py
@@ -18,7 +18,16 @@ def mlp(input_shape: Tuple[int, ...],
     model = Sequential()
     # Don't forget to pass input_shape to the first layer of the model
     ##### Your code below (Lab 1)
+    
+    # creating input layers
+    model.add(Flatten(input_shape=input_shape))
+    # adding fully-connected and dropout layers
+    for i in range(num_layers):        
+        model.add(Dense(layer_size, activation='relu'))
+        model.add(Dropout(dropout_amount))
 
+    model.add(Dense(num_classes, activation='softmax'))
+    
     ##### Your code above (Lab 1)
 
     return model
diff --git a/lab1/text_recognizer/weights/CharacterModel_EmnistDataset_mlp_weights.h5 b/lab1/text_recognizer/weights/CharacterModel_EmnistDataset_mlp_weights.h5
new file mode 100644
index 0000000..1fd5884
Binary files /dev/null and b/lab1/text_recognizer/weights/CharacterModel_EmnistDataset_mlp_weights.h5 differ
diff --git a/lab3/text_recognizer/models/line_model_ctc.py b/lab3/text_recognizer/models/line_model_ctc.py
index e4620a5..179a0fe 100644
--- a/lab3/text_recognizer/models/line_model_ctc.py
+++ b/lab3/text_recognizer/models/line_model_ctc.py
@@ -80,7 +80,17 @@ class LineModelCtc(Model):
 
         # Get the prediction and confidence using softmax_output_fn, passing the right input into it.
         ##### Your code below (Lab 3)
-
+        mode = 0
+        softmax_output = softmax_output_fn([np.array([image]), mode])[0]
+        
+        decode_input_length = np.array([softmax_output.shape[1]])
+        decoded, probas = K.ctc_decode(softmax_output, decode_input_length, greedy=True)
+        
+        artifact = K.eval(decoded[0])[0]
+        pred = ''.join(self.data.mapping[label] for label in artifact).strip()
+        
+        neg_sum_logit = K.eval(probas)[0][0]
+        conf = np.exp(neg_sum_logit) / (1 + np.exp(neg_sum_logit))
         ##### Your code above (Lab 3)
 
         return pred, conf
diff --git a/lab3/text_recognizer/networks/lenet.py b/lab3/text_recognizer/networks/lenet.py
index 3cd0f1a..5a1ecea 100644
--- a/lab3/text_recognizer/networks/lenet.py
+++ b/lab3/text_recognizer/networks/lenet.py
@@ -13,8 +13,8 @@ def lenet(input_shape: Tuple[int, ...], output_shape: Tuple[int, ...]) -> Model:
     if len(input_shape) < 3:
         model.add(Lambda(lambda x: tf.expand_dims(x, -1), input_shape=input_shape))
         input_shape = (input_shape[0], input_shape[1], 1)
-    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))
-    model.add(Conv2D(64, (3, 3), activation='relu'))
+    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=input_shape))
+    model.add(Conv2D(128, (3, 3), activation='relu'))
     model.add(MaxPooling2D(pool_size=(2, 2)))
     model.add(Dropout(0.2))
     model.add(Flatten())
diff --git a/lab3/text_recognizer/networks/line_lstm_ctc.py b/lab3/text_recognizer/networks/line_lstm_ctc.py
index 25c1798..ccbd623 100644
--- a/lab3/text_recognizer/networks/line_lstm_ctc.py
+++ b/lab3/text_recognizer/networks/line_lstm_ctc.py
@@ -35,7 +35,23 @@ def line_lstm_ctc(input_shape, output_shape, window_width=28, window_stride=14):
     # Note that lstms expect a input of shape (num_batch_size, num_timesteps, feature_length).
 
     ##### Your code below (Lab 3)
+    # reshape the image input
+    image_reshaped = Reshape((image_height, image_width, 1))(image_input)
+    # extract image patches
+    image_patches = Lambda(
+        slide_window,
+        arguments={'window_width': window_width, 'window_stride': window_stride}
+    )(image_reshaped)
 
+    # conv over each patch 
+    convnet = lenet((image_height, window_width, 1), (num_classes,)) 
+    convnet = KerasModel(inputs=convnet.inputs, outputs=convnet.layers[-2].output)
+
+    convnet_outputs = TimeDistributed(convnet)(image_patches)
+    
+    lstm_output = lstm_fn(256, return_sequences=True)(convnet_outputs)
+    
+    softmax_output = Dense(num_classes, activation='softmax', name='softmax_output')(lstm_output) 
     ##### Your code above (Lab 3)
 
     input_length_processed = Lambda(
diff --git a/lab3/text_recognizer/weights/LineModelCtc_EmnistLinesDataset_line_lstm_ctc_weights.h5 b/lab3/text_recognizer/weights/LineModelCtc_EmnistLinesDataset_line_lstm_ctc_weights.h5
new file mode 100644
index 0000000..dc79dfa
Binary files /dev/null and b/lab3/text_recognizer/weights/LineModelCtc_EmnistLinesDataset_line_lstm_ctc_weights.h5 differ
diff --git a/lab5/text_recognizer/networks/line_lstm_ctc.py b/lab5/text_recognizer/networks/line_lstm_ctc.py
index 90d7325..5514a4e 100644
--- a/lab5/text_recognizer/networks/line_lstm_ctc.py
+++ b/lab5/text_recognizer/networks/line_lstm_ctc.py
@@ -2,7 +2,7 @@ from boltons.cacheutils import cachedproperty
 import tensorflow as tf
 import tensorflow.keras.backend as K
 from tensorflow.python.client import device_lib
-from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, Input, MaxPooling2D, Permute, RepeatVector, Reshape, TimeDistributed, Lambda, LSTM, GRU, CuDNNLSTM, Bidirectional
+from tensorflow.keras.layers import Conv2D, Dense, Dropout, Flatten, Input, MaxPooling2D, Permute, RepeatVector, Reshape, TimeDistributed, Lambda, LSTM, GRU, CuDNNLSTM, Bidirectional, BatchNormalization
 from tensorflow.keras.models import Sequential
 from tensorflow.keras.models import Model as KerasModel
 
@@ -49,11 +49,19 @@ def line_lstm_ctc(input_shape, output_shape, window_width=28, window_stride=14):
     convnet = KerasModel(inputs=convnet.inputs, outputs=convnet.layers[-2].output)
     convnet_outputs = TimeDistributed(convnet)(image_patches)
     # (num_windows, 128)
-
-    lstm_output = lstm_fn(128, return_sequences=True)(convnet_outputs)
+    
+    drop0 = Dropout(0.2)(convnet_outputs)
+    
+    bn_output1 = BatchNormalization()(drop0)
+    lstm_output1 = Bidirectional(lstm_fn(256, return_sequences=True))(bn_output1)
     # (num_windows, 128)
+    drop1 = Dropout(0.3)(lstm_output1)
+
+    bn_output2 = BatchNormalization()(drop1)
+    lstm_output2 = Bidirectional(lstm_fn(256, return_sequences=True))(bn_output2)
+    drop2 = Dropout(0.3)(lstm_output2)
 
-    softmax_output = Dense(num_classes, activation='softmax', name='softmax_output')(lstm_output)
+    softmax_output = Dense(num_classes, activation='softmax', name='softmax_output')(drop2)
     # (num_windows, num_classes)
     ##### Your code above (Lab 3)
 
